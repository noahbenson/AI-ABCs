{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77ef11d9-7ecd-4ed5-a058-b677bbd32e38",
   "metadata": {},
   "source": [
    "# Other PyTorch Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2daaeca-6797-438d-8025-e2ae6c93fad9",
   "metadata": {},
   "source": [
    "PyTorch has a number of other useful features and utilities as well as a few compantion libraries. Most of these are beyond the scope of this course, but this brief section outlines a few of them and points toward additional resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581aedc4-2c7c-4fdb-a8f6-c89220284f8a",
   "metadata": {},
   "source": [
    "## PyTorch Linear Algebra: `torch.linalg`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334acd8f-97ef-487e-921d-9e1de2d3cb8e",
   "metadata": {},
   "source": [
    "PyTorch's linear algebra subpackage, similar to NumPy's `numpy.linalg`, contains calculations such as matrix inverse and least-squares functions that will respect PyTorch's autograd. This essentially means that you can calculate eigenvalues and perform linear regression as a step in a nonlinear model, and PyTorch will track the gradients for these operations correctly during optimization.\n",
    "\n",
    "See the [`torch.linalg` Reference API](https://docs.pytorch.org/docs/stable/linalg.html) and [this Linear Algebra chapter](https://caam37830.github.io/book/02_linear_algebra/linear_algebra.html) from an online Scientific Computing in Python course by Brad Nelson for some additional information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b270f0-809c-485d-926b-a79bfa6fdb8f",
   "metadata": {},
   "source": [
    "## Train/Test/Validation Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f2e7af-7eaf-454e-8cc7-990f370925fa",
   "metadata": {},
   "source": [
    "PyTorch includes a function in the `torch.utils.data` subpackage for randomly splitting data into train, test, and validation subsets called `random_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90ccd54-dcb7-43b0-94fd-612af47f9b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# Simulate a dataset of 1000 observations and 8 features:\n",
    "n = 1000\n",
    "dataset = torch.randn(n, 8)\n",
    "\n",
    "# Split the dataset into three subsets:\n",
    "(train, test, val) = random_split(dataset, (0.65, 0.2, 0.15))\n",
    "\n",
    "print('train:', len(train))\n",
    "print(' test:', len(test))\n",
    "print('  val:', len(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76b4bf4-62e8-49aa-8987-12b202802386",
   "metadata": {},
   "source": [
    "The returned objects aren't actually the submatrices; rather they are a `Subset` type that stores both the original dataset and the indices of the subselection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e43287-468d-471f-9f51-43b491ac8f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(train))\n",
    "print(len(train.dataset))\n",
    "print(len(train.indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071b441b-aa08-4e75-b923-0ab4e7dd28b8",
   "metadata": {},
   "source": [
    "## PyTorch Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f36f32d-c153-489b-84f6-b090aebeecc2",
   "metadata": {},
   "source": [
    "There is a whole subpackage of PyTorch for probability distributions and calculations related to them. You can find more information in the [API Reference for `torch.distributions`](https://docs.pytorch.org/docs/stable/distributions.html). Let's look at a quick example of an exponential distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3021bfc-4b3c-4330-915b-7611f3f28b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Exponential\n",
    "\n",
    "exp_dist = Exponential(1.5)\n",
    "\n",
    "# Plot the PDF of the exponential distribution.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = torch.linspace(0,10,500)\n",
    "# PyTorch distributions have functions for CDF but the PDF function calculates\n",
    "# the log probability; this is more commonly used in optimization.\n",
    "y = exp_dist.log_prob(x)\n",
    "y = torch.exp(y)\n",
    "plt.plot(x, y, 'k-')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72b587c-6ba4-4056-b9ff-e6192c5c296a",
   "metadata": {},
   "source": [
    "## Torch Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d505b8bc-3fcc-4f5f-8c28-afc2f1868971",
   "metadata": {},
   "source": [
    "Torch Hub allows one to upload and share models with other researchers. There is an interface for loading models from Torch Hub in PyTorch that we will see in the next section ([`torch.hub`](https://docs.pytorch.org/docs/stable/hub.html))."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
